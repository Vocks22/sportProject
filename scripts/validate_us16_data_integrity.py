#!/usr/bin/env python3
"""
Validation de l'int√©grit√© des donn√©es US1.6 - Semaines ISO 8601

Ce script effectue une validation compl√®te de l'int√©grit√© des donn√©es
apr√®s la migration vers les semaines ISO 8601 (lundi-dimanche).

Il v√©rifie:
- Conformit√© ISO 8601 des dates week_start
- Coh√©rence des relations entre tables
- Int√©grit√© r√©f√©rentielle
- Validation des contraintes m√©tier
- D√©tection d'anomalies

Usage:
    python scripts/validate_us16_data_integrity.py [--fix-issues] [--detailed-report]
"""

import sys
import os
import argparse
import json
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict

# Ajouter le r√©pertoire backend au path
backend_path = Path(__file__).resolve().parent.parent / 'src' / 'backend'
sys.path.append(str(backend_path))

from database.config import get_config
from database import db
from models.meal_plan import MealPlan, ShoppingList
from models.shopping_history import ShoppingListHistory, StoreCategory
from utils.date_utils import (
    validate_week_start_iso8601,
    get_monday_of_week,
    format_week_display,
    is_monday
)
from flask import Flask


class DataIntegrityValidator:
    """Validateur d'int√©grit√© des donn√©es US1.6"""
    
    def __init__(self, config_name: str = 'development', verbose: bool = False):
        self.config_name = config_name
        self.verbose = verbose
        
        # Rapport de validation
        self.validation_report = {
            'timestamp': datetime.now().isoformat(),
            'config': config_name,
            'summary': {
                'total_issues': 0,
                'critical_issues': 0,
                'warning_issues': 0,
                'info_issues': 0
            },
            'categories': {},
            'fixed_issues': [],
            'recommendations': []
        }
        
        # Compteurs
        self.stats = {
            'meal_plans_checked': 0,
            'shopping_lists_checked': 0,
            'history_entries_checked': 0,
            'categories_checked': 0
        }
        
        # Initialiser Flask app
        self.app = Flask(__name__)
        config_class = get_config(config_name)
        self.app.config.from_object(config_class)
        db.init_app(self.app)
        
        if verbose:
            print(f"üîß Configuration: {config_name}")
            print(f"üîß Database: {self.app.config['SQLALCHEMY_DATABASE_URI']}")
    
    def log(self, message: str, level: str = 'INFO'):
        """Log avec timestamp"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        if self.verbose or level in ['ERROR', 'WARNING']:
            print(f"[{timestamp}] [{level}] {message}")
    
    def add_issue(self, category: str, severity: str, title: str, description: str, 
                  record_id: Optional[int] = None, table: Optional[str] = None, 
                  fix_sql: Optional[str] = None, metadata: Optional[Dict] = None):
        """Ajoute un probl√®me au rapport"""
        
        if category not in self.validation_report['categories']:
            self.validation_report['categories'][category] = []
        
        issue = {
            'severity': severity,
            'title': title,
            'description': description,
            'timestamp': datetime.now().isoformat(),
        }
        
        if record_id:
            issue['record_id'] = record_id
        if table:
            issue['table'] = table
        if fix_sql:
            issue['fix_sql'] = fix_sql
        if metadata:
            issue['metadata'] = metadata
        
        self.validation_report['categories'][category].append(issue)
        self.validation_report['summary']['total_issues'] += 1
        
        if severity == 'CRITICAL':
            self.validation_report['summary']['critical_issues'] += 1
        elif severity == 'WARNING':
            self.validation_report['summary']['warning_issues'] += 1
        else:
            self.validation_report['summary']['info_issues'] += 1
    
    def validate_week_start_iso8601_compliance(self) -> bool:
        """Valide la conformit√© ISO 8601 des dates week_start"""
        self.log("üîç Validation conformit√© ISO 8601...")
        
        all_valid = True
        
        with self.app.app_context():
            # Valider meal_plans
            meal_plans = MealPlan.query.all()
            self.stats['meal_plans_checked'] = len(meal_plans)
            
            for mp in meal_plans:
                if not mp.week_start:
                    self.add_issue(
                        'iso8601_compliance', 'CRITICAL',
                        f'Meal Plan {mp.id}: week_start NULL',
                        'La date week_start ne peut pas √™tre NULL',
                        record_id=mp.id, table='meal_plans',
                        fix_sql=f"DELETE FROM meal_plans WHERE id = {mp.id}"
                    )
                    all_valid = False
                    
                elif not is_monday(mp.week_start):
                    correct_monday = get_monday_of_week(mp.week_start)
                    weekday_names = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']
                    current_weekday = weekday_names[mp.week_start.weekday()]
                    
                    self.add_issue(
                        'iso8601_compliance', 'CRITICAL',
                        f'Meal Plan {mp.id}: week_start n\'est pas un lundi',
                        f'Date actuelle: {mp.week_start} ({current_weekday}). Devrait √™tre: {correct_monday} (lundi)',
                        record_id=mp.id, table='meal_plans',
                        fix_sql=f"UPDATE meal_plans SET week_start = '{correct_monday}' WHERE id = {mp.id}",
                        metadata={
                            'current_date': mp.week_start.isoformat(),
                            'current_weekday': current_weekday,
                            'correct_date': correct_monday.isoformat()
                        }
                    )
                    all_valid = False
            
            # Valider shopping_lists
            shopping_lists = ShoppingList.query.all()
            self.stats['shopping_lists_checked'] = len(shopping_lists)
            
            for sl in shopping_lists:
                if not sl.week_start:
                    self.add_issue(
                        'iso8601_compliance', 'CRITICAL',
                        f'Shopping List {sl.id}: week_start NULL',
                        'La date week_start ne peut pas √™tre NULL',
                        record_id=sl.id, table='shopping_lists',
                        fix_sql=f"DELETE FROM shopping_lists WHERE id = {sl.id}"
                    )
                    all_valid = False
                    
                elif not is_monday(sl.week_start):
                    correct_monday = get_monday_of_week(sl.week_start)
                    weekday_names = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']
                    current_weekday = weekday_names[sl.week_start.weekday()]
                    
                    self.add_issue(
                        'iso8601_compliance', 'CRITICAL',
                        f'Shopping List {sl.id}: week_start n\'est pas un lundi',
                        f'Date actuelle: {sl.week_start} ({current_weekday}). Devrait √™tre: {correct_monday} (lundi)',
                        record_id=sl.id, table='shopping_lists',
                        fix_sql=f"UPDATE shopping_lists SET week_start = '{correct_monday}' WHERE id = {sl.id}",
                        metadata={
                            'current_date': sl.week_start.isoformat(),
                            'current_weekday': current_weekday,
                            'correct_date': correct_monday.isoformat()
                        }
                    )
                    all_valid = False
        
        if all_valid:
            self.log("‚úÖ Toutes les dates week_start sont conformes ISO 8601")
        else:
            self.log("‚ùå Dates week_start non conformes d√©tect√©es", 'ERROR')
        
        return all_valid
    
    def validate_referential_integrity(self) -> bool:
        """Valide l'int√©grit√© r√©f√©rentielle entre les tables"""
        self.log("üîç Validation int√©grit√© r√©f√©rentielle...")
        
        all_valid = True
        
        with self.app.app_context():
            # V√©rifier shopping_lists -> meal_plans
            shopping_lists = ShoppingList.query.all()
            
            for sl in shopping_lists:
                meal_plan = MealPlan.query.get(sl.meal_plan_id)
                
                if not meal_plan:
                    self.add_issue(
                        'referential_integrity', 'CRITICAL',
                        f'Shopping List {sl.id}: meal_plan orphelin',
                        f'R√©f√©rence vers meal_plan_id {sl.meal_plan_id} qui n\'existe pas',
                        record_id=sl.id, table='shopping_lists',
                        fix_sql=f"DELETE FROM shopping_lists WHERE id = {sl.id}"
                    )
                    all_valid = False
                
                # V√©rifier coh√©rence des dates week_start
                elif sl.week_start != meal_plan.week_start:
                    self.add_issue(
                        'referential_integrity', 'WARNING',
                        f'Shopping List {sl.id}: incoh√©rence date week_start',
                        f'Shopping list week_start: {sl.week_start}, Meal plan week_start: {meal_plan.week_start}',
                        record_id=sl.id, table='shopping_lists',
                        fix_sql=f"UPDATE shopping_lists SET week_start = '{meal_plan.week_start}' WHERE id = {sl.id}",
                        metadata={
                            'shopping_list_date': sl.week_start.isoformat(),
                            'meal_plan_date': meal_plan.week_start.isoformat()
                        }
                    )
                    all_valid = False
            
            # V√©rifier shopping_list_history -> shopping_lists
            history_entries = ShoppingListHistory.query.all()
            self.stats['history_entries_checked'] = len(history_entries)
            
            for history in history_entries:
                shopping_list = ShoppingList.query.get(history.shopping_list_id)
                
                if not shopping_list:
                    self.add_issue(
                        'referential_integrity', 'WARNING',
                        f'History {history.id}: shopping_list orphelin',
                        f'R√©f√©rence vers shopping_list_id {history.shopping_list_id} qui n\'existe pas',
                        record_id=history.id, table='shopping_list_history',
                        fix_sql=f"DELETE FROM shopping_list_history WHERE id = {history.id}"
                    )
                    all_valid = False
        
        if all_valid:
            self.log("‚úÖ Int√©grit√© r√©f√©rentielle valid√©e")
        else:
            self.log("‚ùå Probl√®mes d'int√©grit√© r√©f√©rentielle d√©tect√©s", 'ERROR')
        
        return all_valid
    
    def validate_business_constraints(self) -> bool:
        """Valide les contraintes m√©tier"""
        self.log("üîç Validation contraintes m√©tier...")
        
        all_valid = True
        
        with self.app.app_context():
            # V√©rifier les doublons de meal_plans (user_id + week_start uniques)
            meal_plans_by_user_week = defaultdict(list)
            
            for mp in MealPlan.query.all():
                key = (mp.user_id, mp.week_start)
                meal_plans_by_user_week[key].append(mp)
            
            for (user_id, week_start), meal_plans in meal_plans_by_user_week.items():
                if len(meal_plans) > 1:
                    ids = [str(mp.id) for mp in meal_plans]
                    self.add_issue(
                        'business_constraints', 'WARNING',
                        f'Doublons meal_plans: utilisateur {user_id}, semaine {week_start}',
                        f'Plusieurs meal_plans trouv√©s: IDs {", ".join(ids)}',
                        metadata={
                            'user_id': user_id,
                            'week_start': week_start.isoformat() if week_start else None,
                            'duplicate_ids': ids
                        }
                    )
                    all_valid = False
            
            # V√©rifier les meal_plans dans le futur (plus de 4 semaines)
            max_future_date = date.today() + timedelta(weeks=4)
            future_meal_plans = MealPlan.query.filter(MealPlan.week_start > max_future_date).all()
            
            for mp in future_meal_plans:
                self.add_issue(
                    'business_constraints', 'INFO',
                    f'Meal Plan {mp.id}: planification tr√®s future',
                    f'Meal plan programm√© pour {mp.week_start} (> 4 semaines)',
                    record_id=mp.id, table='meal_plans',
                    metadata={'week_start': mp.week_start.isoformat()}
                )
            
            # V√©rifier les shopping_lists sans items
            empty_shopping_lists = ShoppingList.query.filter(
                (ShoppingList.items_json == '[]') | 
                (ShoppingList.items_json == None) |
                (ShoppingList.items_json == '')
            ).all()
            
            for sl in empty_shopping_lists:
                self.add_issue(
                    'business_constraints', 'WARNING',
                    f'Shopping List {sl.id}: liste vide',
                    'Liste de courses sans articles',
                    record_id=sl.id, table='shopping_lists'
                )
            
            # V√©rifier les valeurs nutritionnelles aberrantes
            for mp in MealPlan.query.all():
                if mp.daily_calories and (mp.daily_calories < 500 or mp.daily_calories > 5000):
                    self.add_issue(
                        'business_constraints', 'WARNING',
                        f'Meal Plan {mp.id}: calories aberrantes',
                        f'Calories quotidiennes: {mp.daily_calories} (normale: 1200-3000)',
                        record_id=mp.id, table='meal_plans',
                        metadata={'daily_calories': mp.daily_calories}
                    )
                
                if mp.daily_protein and (mp.daily_protein < 20 or mp.daily_protein > 300):
                    self.add_issue(
                        'business_constraints', 'WARNING',
                        f'Meal Plan {mp.id}: prot√©ines aberrantes',
                        f'Prot√©ines quotidiennes: {mp.daily_protein}g (normale: 50-200g)',
                        record_id=mp.id, table='meal_plans',
                        metadata={'daily_protein': mp.daily_protein}
                    )
        
        if all_valid:
            self.log("‚úÖ Contraintes m√©tier respect√©es")
        else:
            self.log("‚ö†Ô∏è Violations de contraintes m√©tier d√©tect√©es", 'WARNING')
        
        return all_valid
    
    def validate_data_consistency(self) -> bool:
        """Valide la coh√©rence des donn√©es"""
        self.log("üîç Validation coh√©rence des donn√©es...")
        
        all_valid = True
        
        with self.app.app_context():
            # V√©rifier la coh√©rence des timestamps
            for mp in MealPlan.query.all():
                if mp.created_at and mp.updated_at and mp.created_at > mp.updated_at:
                    self.add_issue(
                        'data_consistency', 'WARNING',
                        f'Meal Plan {mp.id}: timestamps incoh√©rents',
                        f'created_at ({mp.created_at}) > updated_at ({mp.updated_at})',
                        record_id=mp.id, table='meal_plans'
                    )
                    all_valid = False
            
            # V√©rifier la coh√©rence des dates de shopping_lists
            for sl in ShoppingList.query.all():
                if sl.generated_date and sl.last_updated and sl.generated_date > sl.last_updated:
                    self.add_issue(
                        'data_consistency', 'WARNING',
                        f'Shopping List {sl.id}: dates incoh√©rentes',
                        f'generated_date ({sl.generated_date}) > last_updated ({sl.last_updated})',
                        record_id=sl.id, table='shopping_lists'
                    )
                    all_valid = False
                
                # V√©rifier la coh√©rence des dates de completion
                if sl.is_completed and not sl.completion_date:
                    self.add_issue(
                        'data_consistency', 'WARNING',
                        f'Shopping List {sl.id}: completion_date manquante',
                        'Liste marqu√©e comme termin√©e mais sans date de completion',
                        record_id=sl.id, table='shopping_lists',
                        fix_sql=f"UPDATE shopping_lists SET completion_date = last_updated WHERE id = {sl.id}"
                    )
                    all_valid = False
        
        if all_valid:
            self.log("‚úÖ Coh√©rence des donn√©es valid√©e")
        else:
            self.log("‚ö†Ô∏è Probl√®mes de coh√©rence d√©tect√©s", 'WARNING')
        
        return all_valid
    
    def auto_fix_issues(self, dry_run: bool = True) -> int:
        """Corrige automatiquement les probl√®mes r√©parables"""
        if not dry_run:
            self.log("üîß Correction automatique des probl√®mes...")
        else:
            self.log("üîç Simulation de correction (dry-run)...")
        
        fixes_applied = 0
        
        with self.app.app_context():
            for category, issues in self.validation_report['categories'].items():
                for issue in issues:
                    if 'fix_sql' in issue and issue['severity'] in ['CRITICAL', 'WARNING']:
                        try:
                            if not dry_run:
                                db.session.execute(issue['fix_sql'])
                                db.session.commit()
                                
                                self.validation_report['fixed_issues'].append({
                                    'issue': issue,
                                    'fixed_at': datetime.now().isoformat()
                                })
                            
                            fixes_applied += 1
                            self.log(f"  ‚úÖ {'Simul√©' if dry_run else 'Appliqu√©'}: {issue['title']}")
                            
                        except Exception as e:
                            self.log(f"  ‚ùå Erreur correction {issue['title']}: {e}", 'ERROR')
                            if not dry_run:
                                db.session.rollback()
        
        self.log(f"üîß {fixes_applied} corrections {'simul√©es' if dry_run else 'appliqu√©es'}")
        return fixes_applied
    
    def generate_recommendations(self):
        """G√©n√®re des recommandations bas√©es sur les probl√®mes d√©tect√©s"""
        
        recommendations = []
        
        # Analyser les cat√©gories de probl√®mes
        for category, issues in self.validation_report['categories'].items():
            critical_count = sum(1 for issue in issues if issue['severity'] == 'CRITICAL')
            warning_count = sum(1 for issue in issues if issue['severity'] == 'WARNING')
            
            if category == 'iso8601_compliance' and critical_count > 0:
                recommendations.append({
                    'priority': 'HIGH',
                    'title': 'Corriger les dates week_start non conformes ISO 8601',
                    'description': f'{critical_count} dates week_start ne sont pas des lundis. Utiliser le script de migration ou les requ√™tes de correction automatique.',
                    'action': 'Ex√©cuter: python scripts/migrate_to_iso8601_weeks.py --dry-run'
                })
            
            if category == 'referential_integrity' and critical_count > 0:
                recommendations.append({
                    'priority': 'HIGH',
                    'title': 'Nettoyer les r√©f√©rences orphelines',
                    'description': f'{critical_count} enregistrements avec des r√©f√©rences invalides d√©tect√©s.',
                    'action': 'Utiliser l\'option --fix-issues pour supprimer les enregistrements orphelins'
                })
            
            if category == 'business_constraints' and warning_count > 5:
                recommendations.append({
                    'priority': 'MEDIUM',
                    'title': 'R√©viser les contraintes m√©tier',
                    'description': f'{warning_count} violations de contraintes d√©tect√©es. R√©viser les r√®gles de validation.',
                    'action': 'Analyser le rapport d√©taill√© et mettre √† jour les validations applicatives'
                })
        
        # Recommandations g√©n√©rales
        if self.validation_report['summary']['total_issues'] > 10:
            recommendations.append({
                'priority': 'MEDIUM',
                'title': 'Mettre en place une validation automatique',
                'description': 'Int√©grer ce script de validation dans les tests automatis√©s.',
                'action': 'Ajouter validate_us16_data_integrity.py aux scripts de CI/CD'
            })
        
        self.validation_report['recommendations'] = recommendations
    
    def run_full_validation(self, fix_issues: bool = False, dry_run: bool = True) -> bool:
        """Ex√©cute la validation compl√®te"""
        self.log("üöÄ D√©but de la validation compl√®te US1.6")
        
        # 1. Validation ISO 8601
        iso8601_valid = self.validate_week_start_iso8601_compliance()
        
        # 2. Validation int√©grit√© r√©f√©rentielle
        integrity_valid = self.validate_referential_integrity()
        
        # 3. Validation contraintes m√©tier
        business_valid = self.validate_business_constraints()
        
        # 4. Validation coh√©rence des donn√©es
        consistency_valid = self.validate_data_consistency()
        
        # 5. Corrections automatiques si demand√©es
        fixes_applied = 0
        if fix_issues:
            fixes_applied = self.auto_fix_issues(dry_run=dry_run)
        
        # 6. G√©n√©rer des recommandations
        self.generate_recommendations()
        
        # 7. Rapport final
        all_valid = iso8601_valid and integrity_valid and business_valid and consistency_valid
        
        self.log("üìä R√©sum√© de la validation:")
        self.log(f"  üìã Meal plans v√©rifi√©s: {self.stats['meal_plans_checked']}")
        self.log(f"  üõí Shopping lists v√©rifi√©es: {self.stats['shopping_lists_checked']}")
        self.log(f"  üìù Entr√©es historique v√©rifi√©es: {self.stats['history_entries_checked']}")
        self.log(f"  üè™ Cat√©gories v√©rifi√©es: {self.stats['categories_checked']}")
        self.log("")
        self.log(f"  ‚ùå Probl√®mes critiques: {self.validation_report['summary']['critical_issues']}")
        self.log(f"  ‚ö†Ô∏è Avertissements: {self.validation_report['summary']['warning_issues']}")
        self.log(f"  ‚ÑπÔ∏è Informations: {self.validation_report['summary']['info_issues']}")
        
        if fixes_applied > 0:
            self.log(f"  üîß Corrections appliqu√©es: {fixes_applied}")
        
        if all_valid:
            self.log("‚úÖ Validation compl√®te r√©ussie - Aucun probl√®me critique")
        else:
            self.log("‚ùå Probl√®mes d√©tect√©s - Consulter le rapport d√©taill√©", 'WARNING')
        
        return all_valid
    
    def save_report(self, output_file: Optional[str] = None) -> str:
        """Sauvegarde le rapport de validation"""
        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f"us16_validation_report_{timestamp}.json"
        
        # Ajouter les statistiques au rapport
        self.validation_report['stats'] = self.stats
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.validation_report, f, indent=2, ensure_ascii=False, default=str)
        
        self.log(f"üìÑ Rapport sauv√©: {output_file}")
        return output_file


def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(
        description='Validation int√©grit√© donn√©es US1.6',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--fix-issues', action='store_true',
                       help='Corriger automatiquement les probl√®mes r√©parables')
    parser.add_argument('--dry-run', action='store_true', default=True,
                       help='Mode simulation pour les corrections (d√©faut: activ√©)')
    parser.add_argument('--no-dry-run', action='store_true',
                       help='D√©sactiver le mode simulation (corrections r√©elles)')
    parser.add_argument('--detailed-report', action='store_true',
                       help='G√©n√©rer un rapport d√©taill√©')
    parser.add_argument('--output-file',
                       help='Fichier de sortie pour le rapport JSON')
    parser.add_argument('--config', default='development',
                       choices=['development', 'testing', 'production'],
                       help='Configuration √† utiliser')
    parser.add_argument('--verbose', action='store_true',
                       help='Affichage d√©taill√©')
    
    args = parser.parse_args()
    
    # G√©rer les options dry-run
    if args.no_dry_run:
        dry_run = False
    else:
        dry_run = args.dry_run
    
    # Initialiser le validateur
    validator = DataIntegrityValidator(
        config_name=args.config,
        verbose=args.verbose
    )
    
    try:
        # Ex√©cuter la validation
        success = validator.run_full_validation(
            fix_issues=args.fix_issues,
            dry_run=dry_run
        )
        
        # Sauvegarder le rapport si demand√©
        if args.detailed_report:
            report_file = validator.save_report(args.output_file)
            
            # Afficher quelques d√©tails du rapport
            if validator.validation_report['summary']['total_issues'] > 0:
                print("\nüìã D√©tails des probl√®mes:")
                for category, issues in validator.validation_report['categories'].items():
                    if issues:
                        print(f"\n  üìÇ {category.replace('_', ' ').title()}:")
                        for issue in issues[:3]:  # Max 3 exemples
                            print(f"    ‚Ä¢ {issue['title']}")
                        if len(issues) > 3:
                            print(f"    ... et {len(issues) - 3} autres")
            
            # Afficher les recommandations
            if validator.validation_report['recommendations']:
                print("\nüí° Recommandations:")
                for rec in validator.validation_report['recommendations']:
                    priority_icon = 'üî•' if rec['priority'] == 'HIGH' else '‚ö†Ô∏è'
                    print(f"  {priority_icon} {rec['title']}")
                    print(f"     {rec['description']}")
                    if 'action' in rec:
                        print(f"     Action: {rec['action']}")
                    print()
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        validator.log("‚èπÔ∏è Validation interrompue par l'utilisateur", 'WARNING')
        sys.exit(1)
    except Exception as e:
        validator.log(f"üí• Erreur inattendue: {e}", 'ERROR')
        sys.exit(1)


if __name__ == '__main__':
    main()